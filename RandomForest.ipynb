{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8214745d",
   "metadata": {},
   "source": [
    "<h2> <center> <font color = 'Magenta'> Random Forest </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b72f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "from sklearn import metrics\n",
    "from itertools import chain\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b8538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working Directory\n",
    "path = \"C:/Users/Windows/OneDrive - Lamar University/Documents/Springfield/Python/\"\n",
    "train=pd.read_csv('C:/Users/Windows/OneDrive - Lamar University/Documents/Springfield/Python/SVR/Train_COP30_v4.csv')# \n",
    "test=pd.read_csv('C:/Users/Windows/OneDrive - Lamar University/Documents/Springfield/Python/SVR/Test_COP30_v4.csv')# \n",
    "os.chdir(path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f704169",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9be4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b2fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Lookup_Re_ASPECT', 'Lookup_Re_CI', 'Lookup_Re_MBI','Lookup_Re_MRRTF','Lookup_Re_MRVBF','Lookup_Re_MSP', 'Lookup_Re_NH', 'Lookup_Re_NLCD_v3', 'Lookup_Re_SH', 'Lookup_Re_SLOPE', 'Lookup_Re_TPI', 'Lookup_Re_TWI'] # List of Input features for model\n",
    "train_X = train[features] # Dataframe of the data features\n",
    "train_Y = train['value'] # Add Y variable to the input deature datframe\n",
    "#train_X=train.drop(['value'], axis=1, inplace=True)\n",
    "#test_X.head(5)\n",
    "train_X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Lookup_Re_ASPECT', 'Lookup_Re_CI', 'Lookup_Re_MBI','Lookup_Re_MRRTF','Lookup_Re_MRVBF','Lookup_Re_MSP', 'Lookup_Re_NH', 'Lookup_Re_NLCD_v3', 'Lookup_Re_SH', 'Lookup_Re_SLOPE', 'Lookup_Re_TPI', 'Lookup_Re_TWI'] # List of Input features for model\n",
    "test_X = test[features] # Dataframe of the data features\n",
    "test_Y = test['value'] # Add Y variable to the input deature datframe\n",
    "#train_X=train.drop(['value'], axis=1, inplace=True)\n",
    "#test_X.head(5)\n",
    "test_X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a144cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79668ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = (train_X-train_X.min()) / (train_X.max()-train_X.min()) # Normalize the data\n",
    "test_X = (test_X-test_X.min()) / (test_X.max()-test_X.min()) # Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd2e12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc33bc9",
   "metadata": {},
   "source": [
    "<center> <h2> <font color='blue'> Random Forest </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model \n",
    "rf = RandomForestClassifier(n_estimators=892, max_depth=8 random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a940480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to training data\n",
    "rf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961975b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = rf.predict(train_X) # Make Predictions\n",
    "Yprob = rf.predict_proba(train_X) #test output probabilities\n",
    "zz = pd.DataFrame(Yprob)\n",
    "zz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred1 = rf.predict(test_X) # Make Predictions\n",
    "Yprob1 = rf.predict_proba(test_X) #test output probabilities\n",
    "zz1 = pd.DataFrame(Yprob1)\n",
    "zz1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab08f180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Export the first three decision trees from the forest\n",
    "\n",
    "for i in range(3):\n",
    "    tree = rf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=train_X.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ae4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(train_Y, Y_pred)) #Accuracy of the model on training data\n",
    "print(\"Precision:\",metrics.precision_score(train_Y, Y_pred)) #Precision of the model on training data\n",
    "print(\"Recall:\",metrics.recall_score(train_Y, Y_pred)) #Recall of the model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(test_Y, Y_pred1)) #Accuracy of the model on testing data\n",
    "print(\"Precision:\",metrics.precision_score(test_Y, Y_pred1)) #Precision of the model on testing data\n",
    "print(\"Recall:\",metrics.recall_score(test_Y, Y_pred1)) #Recall of the model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_Y, Y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(train_Y, Y_pred) # Calculate confusion matrix for the model\n",
    "cnf_matrix # y_train is going be rows (obs), y_pred (predicted) are cols\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cnf_matrix)\n",
    "disp.plot() #create visualization of confusion matrix\n",
    "plt.title('Confusion matrix for training data')\n",
    "plt.show() # Display the visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fcd35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix1 = metrics.confusion_matrix(test_Y, Y_pred1) # Calculate confusion matrix for the model\n",
    "cnf_matrix1 # y_test is going be rows (obs), y_pred1 (predicted) are cols\n",
    "disp1 = metrics.ConfusionMatrixDisplay(confusion_matrix=cnf_matrix1)\n",
    "disp1.plot() #create visualization of confusion matrix\n",
    "plt.title('Confusion matrix for testing data')\n",
    "plt.show() # Display the visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_proba = rf.predict_proba(train_X)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(train_Y,  Y_pred_proba)\n",
    "auc = metrics.roc_auc_score(train_Y, Y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(round(auc,4)))\n",
    "plt.legend(loc=4)\n",
    "plt.title('ROC curve for training data')\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_proba1 = rf.predict_proba(test_X)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(test_Y,  Y_pred_proba1)\n",
    "auc = metrics.roc_auc_score(test_Y, Y_pred_proba1)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(round(auc,4)))\n",
    "plt.legend(loc=4)\n",
    "plt.title('ROC curve for testing data')\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4459eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series containing feature importances from the model and feature names from the training data\n",
    "feature_importances = pd.Series(best_rf.feature_importances_, index=train_X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Plot a simple bar chart\n",
    "feature_importances.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60798e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all data\n",
    "All_data=pd.read_csv('C:/Users/Windows/OneDrive - Lamar University/Documents/Springfield/Python/SVR/Combine_COP30_v4.csv')#\n",
    "features = ['Lookup_Re_AHS','Lookup_Re_ASPECT', 'Lookup_Re_CI', 'Lookup_Re_MBI','Lookup_Re_MRRTF','Lookup_Re_MRVBF','Lookup_Re_MSP', 'Lookup_Re_NH', 'Lookup_Re_NLCD_v3', 'Lookup_Re_SH', 'Lookup_Re_SLOPE', 'Lookup_Re_TCA', 'Lookup_Re_TPI', 'Lookup_Re_TWI'] # List of Input features for model\n",
    "All_data = All_data[features] # Dataframe of the data features\n",
    "All_data = (All_data-All_data.min()) / (All_data.max()-All_data.min()) # Normalize the data\n",
    "All_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ca189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the y variable for all x variables\n",
    "\n",
    "Y_pred_all = rf.predict(All_data) # predict wholeÂ dataset\n",
    "Yprob_all = rf.predict_proba(All_data) #test output probabilities\n",
    "zz_all = pd.DataFrame(Yprob_all)\n",
    "zz_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0398962",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_proba_all = rf.predict_proba(All_data)[:,1]\n",
    "Y_pred_proba_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7749236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python3 Program to Create list\n",
    "# with integers within given range\n",
    "import numpy as np\n",
    "def createList(r1, r2):\n",
    "    return np.arange(r1, r2+1, 1)\n",
    "     \n",
    "# Driver Code\n",
    "r1, r2 = 1, 2254695\n",
    "listNumber=createList(r1, r2)\n",
    "listNumb=pd.DataFrame(listNumber, columns = ['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f464f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob = pd.DataFrame(Y_pred_proba_all, columns = ['RF_prob_Y'])\n",
    "df_prob = pd.concat([listNumb, df_prob], axis=1)\n",
    "df_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99789908",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob.to_csv('RandomForest_Springfield.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
